admin_email: cloudman@someplace.org
admin_firstname: CloudMan
admin_lastname: Admin
cloudlaunch:
  affinity: {}
  cloudlaunchserver:
    affinity: {}
    celery_app_name: cloudman
    container_name: cloudman-server
    django_dir: /app/cloudman
    django_settings_module: cloudman.settings
    env_prefix: CLOUDMAN
    extra_config_mounts:
    - config_name: '{{ template "cloudman.fullname" . }}-cm-init-config'
      mount_path: /opt/cloudman/
      name: cloudman-extra-config
      read_only: true
    extra_env:
      oidc_auth_uri: '{{.Values.ingress.protocol }}://{{ .Values.global.domain | default
        (index .Values.ingress.hosts 0) }}/auth/realms/master'
      oidc_client_id: cloudman
      oidc_enabled: "True"
      oidc_public_uri: '{{.Values.ingress.protocol }}://{{ .Values.global.domain |
        default (index .Values.ingress.hosts 0) }}/cloudman'
    extra_init_scripts:
      load_bootstrap.sh: |
        #!/bin/sh
        /app/venv/bin/python manage.py import_cloud_data /app/secrets/cm_initial_cluster_data.yaml
        /app/venv/bin/python manage.py create_cluster {{ .Values.global.deployment_name | default .Release.Name }} KUBE_RANCHER /app/secrets/cm_initial_cluster_data.yaml
        /app/venv/bin/python manage.py projman_load_config /opt/cloudman/projman_config.yaml
        /app/venv/bin/python manage.py helmsman_load_config /opt/cloudman/helmsman_config.yaml
    extra_secret_mounts:
    - mount_path: /app/secrets
      name: cloudman-bootstrap
      read_only: true
      secret_name: '{{ template "cloudman.fullname" . }}-secret'
    extraInitContainers:
    - command:
      - /bin/sh
      - /kc-init/update_keycloak.sh
      image: gempesaw/curl-jq
      name: post-install-job
      volumeMounts:
      - mountPath: /kc-init
        name: kc-init
        readOnly: true
    extraVolumeMounts: |
      - name: kubeconfig
        mountPath: /home/cloudman
    extraVolumes: "- name: kubeconfig\n  emptyDir: {}\n- name: kc-init   \n  configMap:
      \  \n    name: kc-init-script  \n"
    fernet_keys: []
    global:
      domain: 192.168.99.100
    image:
      pullPolicy: IfNotPresent
      repository: cloudve/cloudman-server
      tag: latest
    ingress:
      annotations: {}
      enabled: true
      hosts:
      - null
      path: /cloudman
      protocol: https
      tls: []
    initial_data: []
    nameOverride: cloudman
    nodeSelector: {}
    podAnnotations: {}
    postgresql:
      enabled: true
      extraEnv:
      - name: KEYCLOAK_DB_PASSWORD
        valueFrom:
          secretKeyRef:
            key: postgres-keycloak-password
            name: '{{ .Release.Name }}-postgres-keycloak-password'
      global:
        domain: 192.168.99.100
        postgresql: {}
      image:
        debug: false
        pullPolicy: IfNotPresent
        registry: docker.io
        repository: bitnami/postgresql
        tag: 11.6.0-debian-10-r5
      initdbScriptsSecret: '{{ .Release.Name }}-keycloak-initdb'
      ldap:
        baseDN: ""
        bind_password: null
        bindDN: ""
        enabled: false
        port: ""
        prefix: ""
        scheme: ""
        search_attr: ""
        search_filter: ""
        server: ""
        suffix: ""
        tls: false
        url: ""
      livenessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      master:
        affinity: {}
        annotations: {}
        extraInitContainers: ""
        extraVolumeMounts: []
        extraVolumes: []
        labels: {}
        nodeSelector: {}
        podAnnotations: {}
        podLabels: {}
        priorityClassName: ""
        tolerations: []
      metrics:
        enabled: false
        image:
          pullPolicy: IfNotPresent
          registry: docker.io
          repository: bitnami/postgres-exporter
          tag: 0.8.0-debian-10-r4
        livenessProbe:
          enabled: true
          failureThreshold: 6
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        prometheusRule:
          additionalLabels: {}
          enabled: false
          namespace: ""
          rules: []
        readinessProbe:
          enabled: true
          failureThreshold: 6
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        securityContext:
          enabled: false
          runAsUser: 1001
        service:
          annotations:
            prometheus.io/port: "9187"
            prometheus.io/scrape: "true"
          loadBalancerIP: null
          type: ClusterIP
        serviceMonitor:
          additionalLabels: {}
          enabled: false
      networkPolicy:
        allowExternal: true
        enabled: false
      persistence:
        accessMode: ReadWriteMany
        accessModes:
        - ReadWriteOnce
        annotations: {}
        enabled: true
        mountPath: /bitnami/postgresql
        size: 8Gi
        subPath: ""
      postgresqlDataDir: /bitnami/postgresql/data
      postgresqlDatabase: cloudman
      postgresqlUsername: cloudman
      readinessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      replication:
        applicationName: my_application
        enabled: false
        numSynchronousReplicas: 0
        password: repl_password
        slaveReplicas: 1
        synchronousCommit: "off"
        user: repl_user
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
      securityContext:
        enabled: true
        fsGroup: 1001
        runAsUser: 1001
      service:
        annotations: {}
        port: 5432
        type: ClusterIP
      serviceAccount:
        enabled: false
      shmVolume:
        chmod:
          enabled: true
        enabled: true
      slave:
        affinity: {}
        annotations: {}
        extraInitContainers: ""
        extraVolumeMounts: []
        extraVolumes: []
        labels: {}
        nodeSelector: {}
        podAnnotations: {}
        podLabels: {}
        priorityClassName: ""
        tolerations: []
      updateStrategy:
        type: RollingUpdate
      volumePermissions:
        enabled: true
        image:
          pullPolicy: Always
          registry: docker.io
          repository: bitnami/minideb
          tag: stretch
        securityContext:
          runAsUser: 0
    rabbitmq:
      rabbitmqErlangCookie: mustRemainSameBetweenUpgrades
      rabbitmqUsername: notAGuest
      replicaCount: 1
    rabbitmq-ha:
      advancedConfig: ""
      busyboxImage:
        pullPolicy: IfNotPresent
        repository: busybox
        tag: 1.30.1
      clusterDomain: cluster.local
      definitions:
        bindings: ""
        exchanges: ""
        globalParameters: ""
        parameters: ""
        permissions: ""
        policies: ""
        queues: ""
        users: ""
        vhosts: ""
      definitionsSource: definitions.json
      env: {}
      existingConfigMap: false
      existingSecret: ""
      extraConfig: ""
      extraContainers: []
      extraInitContainers: []
      extraLabels: {}
      extraPlugins: |
        rabbitmq_shovel,
        rabbitmq_shovel_management,
        rabbitmq_federation,
        rabbitmq_federation_management,
      extraVolumeMounts: []
      extraVolumes: []
      forceBoot: false
      global:
        domain: 192.168.99.100
      image:
        pullPolicy: IfNotPresent
        repository: rabbitmq
        tag: 3.8.0-alpine
      ingress:
        annotations: {}
        enabled: false
        path: /
        tls: false
        tlsSecret: myTlsSecret
      initContainer:
        resources: {}
      lifecycle: {}
      livenessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - 'wget -O - -q --header "Authorization: Basic `echo -n \"$RABBIT_MANAGEMENT_USER:$RABBIT_MANAGEMENT_PASSWORD\"
            | base64`" http://localhost:15672/api/healthchecks/node | grep -qF "{\"status\":\"ok\"}"'
        failureThreshold: 6
        initialDelaySeconds: 120
        periodSeconds: 10
        timeoutSeconds: 5
      managementUsername: management
      nodeSelector: {}
      persistentVolume:
        accessModes:
        - ReadWriteOnce
        annotations: {}
        enabled: false
        name: data
        size: 8Gi
      podAnnotations: {}
      podAntiAffinity: soft
      podAntiAffinityTopologyKey: kubernetes.io/hostname
      podDisruptionBudget: {}
      podManagementPolicy: OrderedReady
      prometheus:
        exporter:
          capabilities: bert,no_sort
          enabled: false
          env: {}
          image:
            pullPolicy: IfNotPresent
            repository: kbudde/rabbitmq-exporter
            tag: v0.29.0
          port: 9090
          resources: {}
        operator:
          alerts:
            enabled: true
            labels: {}
            selector:
              role: alert-rules
          enabled: true
          serviceMonitor:
            interval: 10s
            namespace: monitoring
            selector:
              prometheus: kube-prometheus
      rabbitmqAmqpsSupport:
        amqpsNodePort: 5671
        config: |
          # listeners.ssl.default             = 5671
          # ssl_options.cacertfile            = /etc/cert/cacert.pem
          # ssl_options.certfile              = /etc/cert/cert.pem
          # ssl_options.keyfile               = /etc/cert/key.pem
          # ssl_options.verify                = verify_peer
          # ssl_options.fail_if_no_peer_cert  = false
        enabled: false
      rabbitmqAuth:
        config: |
          # auth_mechanisms.1 = PLAIN
          # auth_mechanisms.2 = AMQPLAIN
          # auth_mechanisms.3 = EXTERNAL
        enabled: false
      rabbitmqAuthHTTP:
        config: |
          # auth_backends.1 = http
          # auth_http.user_path     = http://some-server/auth/user
          # auth_http.vhost_path    = http://some-server/auth/vhost
          # auth_http.resource_path = http://some-server/auth/resource
          # auth_http.topic_path    = http://some-server/auth/topic
        enabled: false
      rabbitmqCert:
        cacertfile: ""
        certfile: ""
        enabled: false
        existingSecret: ""
        keyfile: ""
      rabbitmqClusterPartitionHandling: autoheal
      rabbitmqEpmdPort: 4369
      rabbitmqHipeCompile: false
      rabbitmqLDAPPlugin:
        config: |
          # auth_backends.1 = ldap
          # auth_ldap.servers.1  = my-ldap-server
          # auth_ldap.user_dn_pattern = cn=${username},ou=People,dc=example,dc=com
          # auth_ldap.use_ssl    = false
          # auth_ldap.port       = 389
          # auth_ldap.log        = false
        enabled: false
      rabbitmqMQTTPlugin:
        config: |
          # mqtt.default_user     = guest
          # mqtt.default_pass     = guest
          # mqtt.allow_anonymous  = true
        enabled: false
      rabbitmqManagerPort: 15672
      rabbitmqMemoryHighWatermark: 256MB
      rabbitmqMemoryHighWatermarkType: absolute
      rabbitmqNodePort: 5672
      rabbitmqPrometheusPlugin:
        config: |
          ## prometheus.path and prometheus.tcp.port can be set above
        enabled: false
        nodePort: null
        path: /metrics
        port: 15692
      rabbitmqSTOMPPlugin:
        config: |
          # stomp.default_user = guest
          # stomp.default_pass = guest
        enabled: false
      rabbitmqUsername: guest
      rabbitmqVhost: /
      rabbitmqWebMQTTPlugin:
        config: |
          # web_mqtt.ssl.port       = 12345
          # web_mqtt.ssl.backlog    = 1024
          # web_mqtt.ssl.certfile   = /etc/cert/cacert.pem
          # web_mqtt.ssl.keyfile    = /etc/cert/cert.pem
          # web_mqtt.ssl.cacertfile = /etc/cert/key.pem
          # web_mqtt.ssl.password   = changeme
        enabled: false
      rabbitmqWebSTOMPPlugin:
        config: |
          # web_stomp.ws_frame = binary
          # web_stomp.cowboy_opts.max_keepalive = 10
        enabled: false
      rbac:
        create: true
      readinessProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - 'wget -O - -q --header "Authorization: Basic `echo -n \"$RABBIT_MANAGEMENT_USER:$RABBIT_MANAGEMENT_PASSWORD\"
            | base64`" http://localhost:15672/api/healthchecks/node | grep -qF "{\"status\":\"ok\"}"'
        failureThreshold: 6
        initialDelaySeconds: 20
        periodSeconds: 5
        timeoutSeconds: 3
      replicaCount: 3
      resources: {}
      securityContext:
        fsGroup: 101
        runAsGroup: 101
        runAsNonRoot: true
        runAsUser: 100
      service:
        amqpNodePort: null
        annotations: {}
        clusterIP: None
        epmdNodePort: null
        externalIPs: []
        loadBalancerIP: ""
        loadBalancerSourceRanges: []
        managerNodePort: null
        type: ClusterIP
      serviceAccount:
        automountServiceAccountToken: true
        create: true
      statefulSetAnnotations: {}
      terminationGracePeriodSeconds: 10
      tolerations: []
      updateStrategy: OnDelete
    replicaCount: 1
    resources: {}
    service:
      port: 8000
      type: ClusterIP
    tolerations: []
  container_name: cloudman-ui
  global:
    domain: 192.168.99.100
  image:
    pullPolicy: IfNotPresent
    repository: cloudve/cloudman-ui
    tag: latest
  ingress:
    annotations:
      kubernetes.io/ingress.class: nginx
    enabled: true
    hosts:
    - null
    path: /
    tls: []
  nameOverride: cloudman
  nodeSelector: {}
  podAnnotations: {}
  replicaCount: 1
  resources: {}
  service:
    port: 80
    type: ClusterIP
  tolerations: []
cm_initial_cluster_data: null
global:
  domain: 192.168.99.100
helmsman_config:
  charts:
    cvmfs:
      name: cloudve/galaxy-cvmfs-csi
      namespace: cvmfs
      values:
        cache:
          size: 15000
    galaxy:
      name: cloudve/galaxy
      namespace: initial
      oidc_client:
        client_id: galaxy-auth
        public_client: false
        redirect_uris:
        - '{{ include "cloudman.root_url" . }}/authnz/custos/callback'
      tplValues:
        configs:
          oidc_backends_config.xml: |
            <?xml version="1.0"?>
            <OIDC>
                <provider name="custos">
                    <url>{{ include "cloudman.root_url" . }}/auth</url>
                    <client_id>{{ .Values.helmsman_config.charts.galaxy.oidc_client.client_id }}</client_id>
                    <client_secret>{{ .Values.helmsman_config.charts.galaxy.oidc_client.client_secret }}</client_secret>
                    <redirect_uri>{{ include "cloudman.root_url" . }}/authnz/custos/callback</redirect_uri>
                    <realm>master</realm>
                </provider>
            </OIDC>
        influxdb:
          database: '{{ include "cloudman.influxdb_database" . }}'
          password: '{{ .Values.influxdb.setDefaultUser.password }}'
          url: '{{ include "cloudman.influxdb_url_cluster" . }}'
          username: '{{ .Values.influxdb.setDefaultUser.username }}'
      values:
        configs:
          galaxy.yml:
            galaxy:
              enable_oidc: true
              oidc_backends_config_file: /galaxy/server/config/oidc_backends_config.xml
              oidc_config_file: /galaxy/server/config/oidc_config.xml
          oidc_config.xml: |
            <?xml version="1.0"?>
            <OIDC>
                <Setter Property="VERIFY_SSL" Value="False" Type="bool"/>
                <Setter Property="REQUESTS_TIMEOUT" Value="3600" Type="float"/>
                <Setter Property="ID_TOKEN_MAX_AGE" Value="3600" Type="float"/>
            </OIDC>
        image:
          repository: galaxy/galaxy-k8s
          tag: 19.09
        ingress:
          path: /initial/galaxy
        persistence:
          storageClass: nfs
        postgresql:
          persistence:
            storageClass: ebs
  repositories:
  - name: cloudve
    url: https://raw.githubusercontent.com/CloudVE/helm-charts/master/
  - name: jupyterhub
    url: https://jupyterhub.github.io/helm-chart/
influxdb:
  affinity: {}
  backup:
    annotations: {}
    enabled: false
    schedule: 0 0 * * *
  config:
    admin:
      bind_address: 8083
      enabled: false
      https_certificate: /etc/ssl/influxdb.pem
      https_enabled: false
    collectd:
      auth_file: /etc/collectd/auth_file
      batch_pending: 10
      batch_size: 5000
      batch_timeout: 10s
      bind_address: 25826
      database: collectd
      enabled: false
      read_buffer: 0
      retention_policy: autogen
      security_level: none
      typesdb: /usr/share/collectd/types.db
    continuous_queries:
      enabled: true
      log_enabled: true
      run_interval: 1s
    coordinator:
      log_queries_after: 0s
      max_concurrent_queries: 0
      max_select_buckets: 0
      max_select_point: 0
      max_select_series: 0
      query_timeout: 0s
      write_timeout: 10s
    data:
      cache_max_memory_size: 1073741824
      cache_snapshot_memory_size: 26214400
      cache_snapshot_write_cold_duration: 10m0s
      compact_full_write_cold_duration: 4h0m0s
      index_version: inmem
      max_series_per_database: 1000000
      max_values_per_tag: 100000
      query_log_enabled: true
      trace_logging_enabled: false
    graphite:
      batch_pending: 10
      batch_size: 5000
      batch_timeout: 1s
      bind_address: 2003
      consistency_level: one
      database: graphite
      enabled: false
      protocol: tcp
      retention_policy: autogen
      separator: .
      udp_read_buffer: 0
    http:
      auth_enabled: false
      bind_address: 8086
      bind_socket: /var/run/influxdb.sock
      enabled: true
      flux_enabled: true
      https_certificate: /etc/ssl/influxdb.pem
      https_enabled: false
      https_private_key: ""
      log_enabled: true
      max_connection_limit: 0
      max_row_limit: 10000
      pprof_enabled: true
      realm: InfluxDB
      shared_secret: beetlejuicebeetlejuicebeetlejuice
      unix_socket_enabled: false
      write_tracing: false
    logging:
      format: auto
      level: info
      supress_logo: false
    meta:
      logging_enabled: true
      retention_autocreate: true
    monitor:
      store_database: _internal
      store_enabled: true
      store_interval: 10s
    opentsdb:
      batch_pending: 5
      batch_size: 1000
      batch_timeout: 1s
      bind_address: 4242
      certificate: /etc/ssl/influxdb.pem
      consistency_level: one
      database: opentsdb
      enabled: false
      log_point_errors: true
      retention_policy: autogen
      tls_enabled: false
    reporting_disabled: false
    retention:
      check_interval: 30m0s
      enabled: true
    rpc:
      bind_address: 8088
      enabled: true
    shard_precreation:
      advance_period: 30m0s
      check_interval: 10m0s
      enabled: true
    storage_directory: /var/lib/influxdb
    subscriber:
      ca_certs: ""
      enabled: true
      http_timeout: 30s
      insecure_skip_verify: false
      write_buffer_size: 1000
      write_concurrency: 40
    udp:
      batch_pending: 10
      batch_size: 5000
      batch_timeout: 1s
      bind_address: 8089
      database: udp
      enabled: false
      precision: ns
      read_buffer: 0
      retention_policy: autogen
  env: {}
  global:
    domain: 192.168.99.100
  image:
    pullPolicy: IfNotPresent
    repository: influxdb
    tag: 1.7.6-alpine
  ingress:
    annotations: null
    enabled: false
    hostname: influxdb.foobar.com
    tls: false
  initScripts:
    enabled: true
    scripts:
      init.iql: |+
        CREATE DATABASE "telegraf" WITH DURATION 30d REPLICATION 1 NAME "rp_30d"

  livenessProbe:
    probePath: /ping
  nodeSelector: {}
  persistence:
    accessMode: ReadWriteOnce
    annotations: null
    enabled: true
    size: 8Gi
    storageClass: ebs
  podAnnotations: {}
  readinessProbe:
    probePath: /ping
  resources: {}
  service:
    type: ClusterIP
  setDefaultUser:
    activeDeadline: 300
    enabled: true
    image: appropriate/curl:latest
    password: changeme
    restartPolicy: OnFailure
    user:
      privileges: WITH ALL PRIVILEGES
      username: admin
    username: admin
  startupProbe:
    enabled: false
    probePath: /ping
  tolerations: []
keycloak:
  clusterDomain: cluster.local
  global:
    domain: 192.168.99.100
  init:
    image:
      pullPolicy: IfNotPresent
      repository: busybox
      tag: 1.31
    resources: {}
  keycloak:
    affinity: |
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                {{- include "keycloak.selectorLabels" . | nindent 10 }}
              matchExpressions:
                - key: role
                  operator: NotIn
                  values:
                    - test
            topologyKey: kubernetes.io/hostname
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  {{- include "keycloak.selectorLabels" . | nindent 12 }}
                matchExpressions:
                  - key: role
                    operator: NotIn
                    values:
                      - test
              topologyKey: failure-domain.beta.kubernetes.io/zone
    basepath: auth
    cli:
      custom: ""
      datasource: |
        {{ .Files.Get "scripts/datasource.cli" }}
      enabled: true
      ha: |
        {{ .Files.Get "scripts/ha.cli" }}
      logging: |
        {{ .Files.Get "scripts/logging.cli" }}
      nodeIdentifier: |
        {{ .Files.Get "scripts/node-identifier.cli" }}
    containerSecurityContext:
      runAsNonRoot: true
      runAsUser: 1000
    enableServiceLinks: false
    existingSecret: ""
    existingSecretKey: password
    extraArgs: ""
    extraContainers: ""
    extraEnv: |
      - name: DB_ADDR
        value: "{{ .Release.Name }}-postgresql"
      - name: PROXY_ADDRESS_FORWARDING
        value: "true"
    extraInitContainers: |
      - name: theme-provider
        image: cloudve/gvl-keycloak-theme:latest
        imagePullPolicy: IfNotPresent
        command:
          - sh
        args:
          - -c
          - |
            echo "Copying theme..."
            cp -R /customtheme/* /theme
            echo "done."
        volumeMounts:
          - name: theme
            mountPath: /theme
    extraPorts: ""
    extraVolumeMounts: |
      - name: theme
        mountPath: /opt/jboss/keycloak/themes/keycloak
    extraVolumes: |
      - name: theme
        emptyDir: {}
    hostAliases: []
    image:
      pullPolicy: IfNotPresent
      pullSecrets: []
      repository: jboss/keycloak
      tag: 7.0.0
    ingress:
      annotations: {}
      enabled: true
      hosts:
      - null
      labels: {}
      path: /auth
      tls: []
    jgroups:
      discoveryProperties: |
        "dns_query={{ template "keycloak.fullname" . }}-headless.{{ .Release.Namespace }}.svc.{{ .Values.clusterDomain }}"
      discoveryProtocol: dns.DNS_PING
    lifecycleHooks: |
      # postStart:
      #   exec:
      #     command: ["/bin/sh", "-c", "ls"]
    livenessProbe: |
      httpGet:
        path: {{ if ne .Values.keycloak.basepath "" }}/{{ .Values.keycloak.basepath }}{{ end }}/
        port: http
      initialDelaySeconds: 300
      timeoutSeconds: 5
    nodeSelector: {}
    password: changeMe
    persistence:
      dbHost: mykeycloak
      dbName: keycloak
      dbPassword: ""
      dbPort: 5432
      dbUser: keycloak
      dbVendor: postgres
      deployPostgres: false
      existingSecret: '{{ .Release.Name }}-postgres-keycloak-password'
      existingSecretKey: postgres-keycloak-password
    podAnnotations: {}
    podDisruptionBudget: {}
    podLabels: {}
    priorityClassName: ""
    readinessProbe: |
      httpGet:
        path: {{ if ne .Values.keycloak.basepath "" }}/{{ .Values.keycloak.basepath }}{{ end }}/realms/master
        port: http
      initialDelaySeconds: 30
      timeoutSeconds: 1
    replicas: 1
    resources: {}
    restartPolicy: Always
    route:
      annotations: {}
      enabled: false
      host: null
      labels: {}
      path: /
      tls:
        enabled: true
        insecureEdgeTerminationPolicy: Redirect
        termination: edge
    securityContext:
      fsGroup: 1000
    service:
      annotations: {}
      httpNodePort: ""
      httpPort: 80
      httpsNodePort: ""
      httpsPort: 8443
      jgroupsPort: 7600
      labels: {}
      type: ClusterIP
    serviceAccount:
      create: false
      name: null
    startupScripts: {}
    tolerations: []
    username: admin
  postgresql:
    extraEnv: {}
    global:
      domain: 192.168.99.100
      postgresql: {}
    image:
      debug: false
      pullPolicy: IfNotPresent
      registry: docker.io
      repository: bitnami/postgresql
      tag: 11.5.0-debian-9-r60
    livenessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 30
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    master:
      affinity: {}
      extraVolumeMounts: []
      extraVolumes: []
      nodeSelector: {}
      podAnnotations: {}
      podLabels: {}
      tolerations: []
    metrics:
      enabled: false
      image:
        pullPolicy: IfNotPresent
        registry: docker.io
        repository: bitnami/postgres-exporter
        tag: 0.5.1-debian-9-r73
      livenessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      readinessProbe:
        enabled: true
        failureThreshold: 6
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      securityContext:
        enabled: false
        runAsUser: 1001
      service:
        annotations:
          prometheus.io/port: "9187"
          prometheus.io/scrape: "true"
        loadBalancerIP: null
        type: ClusterIP
      serviceMonitor:
        additionalLabels: {}
        enabled: false
    networkPolicy:
      allowExternal: true
      enabled: false
    persistence:
      accessModes:
      - ReadWriteOnce
      annotations: {}
      enabled: false
      mountPath: /bitnami/postgresql
      size: 8Gi
      subPath: ""
    postgresqlDataDir: /bitnami/postgresql/data
    postgresqlDatabase: keycloak
    postgresqlPassword: ""
    postgresqlUsername: keycloak
    readinessProbe:
      enabled: true
      failureThreshold: 6
      initialDelaySeconds: 5
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    replication:
      applicationName: my_application
      enabled: false
      numSynchronousReplicas: 0
      password: repl_password
      slaveReplicas: 1
      synchronousCommit: "off"
      user: repl_user
    resources:
      requests:
        cpu: 250m
        memory: 256Mi
    securityContext:
      enabled: true
      fsGroup: 1001
      runAsUser: 1001
    service:
      annotations: {}
      port: 5432
      type: ClusterIP
    serviceAccount:
      enabled: false
    slave:
      affinity: {}
      extraVolumeMounts: []
      extraVolumes: []
      nodeSelector: {}
      podAnnotations: {}
      podLabels: {}
      tolerations: []
    updateStrategy:
      type: RollingUpdate
    volumePermissions:
      enabled: true
      image:
        pullPolicy: Always
        registry: docker.io
        repository: bitnami/minideb
        tag: stretch
      securityContext:
        runAsUser: 0
  test:
    containerSecurityContext:
      runAsNonRoot: true
      runAsUser: 1000
    enabled: true
    image:
      pullPolicy: IfNotPresent
      repository: unguiculus/docker-python3-phantomjs-selenium
      tag: v1
    securityContext:
      fsGroup: 1000
projman_config:
  projects:
  - name: initial
prometheus:
  grafana:
    adminPassword: changeme
    grafana.ini:
      auth:
        disable_login_form: true
        disable_signout_menu: true
        oauth_auto_login: true
      auth.anonymous:
        enabled: false
      auth.generic_oauth:
        allow_sign_up: true
        api_url: https://{{ .Values.global.domain }}/auth/realms/master/protocol/openid-connect/userinfo
        auth_url: https://{{ .Values.global.domain }}/auth/realms/master/protocol/openid-connect/auth
        client_id: cloudman
        enabled: true
        tls_skip_verify_insecure: true
        token_url: https://{{ .Values.global.domain }}/auth/realms/master/protocol/openid-connect/token
      security:
        allow_embedding: true
      server:
        root_url: https://{{ .Values.global.domain }}/grafana
        serve_from_sub_path: true
    ingress:
      enabled: true
      hosts:
      - null
      path: /grafana
    sidecar:
      dashboards:
        searchNamespace: ALL
prometheus-operator:
  additionalPrometheusRules: []
  alertmanager:
    alertmanagerSpec:
      additionalPeers: []
      affinity: {}
      configMaps: []
      containers: []
      externalUrl: null
      image:
        repository: quay.io/prometheus/alertmanager
        tag: v0.19.0
      listenLocal: false
      logFormat: logfmt
      logLevel: info
      nodeSelector: {}
      paused: false
      podAntiAffinity: ""
      podAntiAffinityTopologyKey: kubernetes.io/hostname
      podMetadata: {}
      portName: web
      priorityClassName: ""
      replicas: 1
      resources: {}
      retention: 120h
      routePrefix: /
      secrets: []
      securityContext:
        fsGroup: 2000
        runAsNonRoot: true
        runAsUser: 1000
      storage: {}
      tolerations: []
      useExistingSecret: false
    config:
      global:
        resolve_timeout: 5m
      receivers:
      - name: "null"
      route:
        group_by:
        - job
        group_interval: 5m
        group_wait: 30s
        receiver: "null"
        repeat_interval: 12h
        routes:
        - match:
            alertname: Watchdog
          receiver: "null"
    enabled: true
    ingress:
      annotations: {}
      enabled: false
      hosts: []
      labels: {}
      paths: []
      tls: []
    podDisruptionBudget:
      enabled: false
      maxUnavailable: ""
      minAvailable: 1
    secret:
      annotations: {}
    service:
      annotations: {}
      clusterIP: ""
      externalIPs: []
      labels: {}
      loadBalancerIP: ""
      loadBalancerSourceRanges: []
      nodePort: 30903
      port: 9093
      type: ClusterIP
    serviceAccount:
      create: true
      name: ""
    serviceMonitor:
      interval: ""
      metricRelabelings: []
      relabelings: []
      selfMonitor: true
    templateFiles: {}
    tplConfig: false
  commonLabels: {}
  coreDns:
    enabled: true
    service:
      port: 9153
      targetPort: 9153
    serviceMonitor:
      interval: ""
      metricRelabelings: []
      relabelings: []
  defaultRules:
    annotations: {}
    appNamespacesTarget: .*
    create: true
    labels: {}
    rules:
      alertmanager: true
      etcd: true
      general: true
      k8s: true
      kubeApiserver: true
      kubePrometheusNodeAlerting: true
      kubePrometheusNodeRecording: true
      kubeScheduler: true
      kubernetesAbsent: true
      kubernetesApps: true
      kubernetesResources: true
      kubernetesStorage: true
      kubernetesSystem: true
      network: true
      node: true
      prometheus: true
      prometheusOperator: true
      time: true
    runbookUrl: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#
  fullnameOverride: ""
  global:
    domain: 192.168.99.100
    imagePullSecrets: []
    rbac:
      create: true
      pspEnabled: true
  grafana:
    additionalDataSources: []
    admin:
      existingSecret: ""
      passwordKey: admin-password
      userKey: admin-user
    adminPassword: prom-operator
    adminUser: admin
    affinity: {}
    dashboardProviders: {}
    dashboards: {}
    dashboardsConfigMaps: {}
    datasources: {}
    defaultDashboardsEnabled: true
    deploymentStrategy:
      type: RollingUpdate
    downloadDashboards:
      env: {}
    downloadDashboardsImage:
      pullPolicy: IfNotPresent
      repository: appropriate/curl
      tag: latest
    enabled: true
    env: {}
    envFromSecret: ""
    envRenderSecret: {}
    envValueFrom: {}
    extraConfigmapMounts: []
    extraContainers: ""
    extraEmptyDirMounts: []
    extraInitContainers: []
    extraSecretMounts: []
    extraVolumeMounts: []
    global:
      domain: 192.168.99.100
      imagePullSecrets: []
      rbac:
        create: true
        pspEnabled: true
    grafana.ini:
      analytics:
        check_for_updates: true
      grafana_net:
        url: https://grafana.net
      log:
        mode: console
      paths:
        data: /var/lib/grafana/data
        logs: /var/log/grafana
        plugins: /var/lib/grafana/plugins
        provisioning: /etc/grafana/provisioning
    image:
      pullPolicy: IfNotPresent
      repository: grafana/grafana
      tag: 6.5.2
    ingress:
      annotations: {}
      enabled: false
      extraPaths: []
      hosts: []
      labels: {}
      path: /
      tls: []
    initChownData:
      enabled: true
      image:
        pullPolicy: IfNotPresent
        repository: busybox
        tag: "1.30"
      resources: {}
    ldap:
      config: ""
      enabled: false
      existingSecret: ""
    livenessProbe:
      failureThreshold: 10
      httpGet:
        path: /api/health
        port: 3000
      initialDelaySeconds: 60
      timeoutSeconds: 30
    namespaceOverride: ""
    nodeSelector: {}
    notifiers: {}
    persistence:
      accessModes:
      - ReadWriteOnce
      enabled: false
      finalizers:
      - kubernetes.io/pvc-protection
      size: 10Gi
      type: pvc
    plugins: []
    podDisruptionBudget: {}
    podPortName: grafana
    rbac:
      create: true
      extraClusterRoleRules: []
      extraRoleRules: []
      namespaced: false
      pspEnabled: true
      pspUseAppArmor: true
    readinessProbe:
      httpGet:
        path: /api/health
        port: 3000
    replicas: 1
    resources: {}
    securityContext:
      fsGroup: 472
      runAsUser: 472
    service:
      annotations: {}
      labels: {}
      port: 80
      portName: service
      targetPort: 3000
      type: ClusterIP
    serviceAccount:
      create: true
      name: null
      nameTest: null
    serviceMonitor:
      interval: ""
      metricRelabelings: []
      relabelings: []
      selfMonitor: true
    sidecar:
      dashboards:
        SCProvider: true
        defaultFolderName: null
        enabled: true
        folder: /tmp/dashboards
        label: grafana_dashboard
        provider:
          allowUiUpdates: false
          disableDelete: false
          folder: ""
          name: sidecarProvider
          orgid: 1
          type: file
        searchNamespace: null
      datasources:
        annotations: {}
        createPrometheusReplicasDatasources: false
        defaultDatasourceEnabled: true
        enabled: true
        label: grafana_datasource
        searchNamespace: null
      image: kiwigrid/k8s-sidecar:0.1.20
      imagePullPolicy: IfNotPresent
      resources: {}
    smtp:
      existingSecret: ""
      passwordKey: password
      userKey: user
    testFramework:
      enabled: true
      image: dduportal/bats
      securityContext: {}
      tag: 0.4.0
    tolerations: []
  kube-state-metrics:
    affinity: {}
    collectors:
      certificatesigningrequests: true
      configmaps: true
      cronjobs: true
      daemonsets: true
      deployments: true
      endpoints: true
      horizontalpodautoscalers: true
      ingresses: true
      jobs: true
      limitranges: true
      mutatingwebhookconfigurations: false
      namespaces: true
      networkpolicies: false
      nodes: true
      persistentvolumeclaims: true
      persistentvolumes: true
      poddisruptionbudgets: true
      pods: true
      replicasets: true
      replicationcontrollers: true
      resourcequotas: true
      secrets: true
      services: true
      statefulsets: true
      storageclasses: true
      validatingwebhookconfigurations: false
      verticalpodautoscalers: false
      volumeattachements: false
    customLabels: {}
    global:
      domain: 192.168.99.100
      imagePullSecrets: []
      rbac:
        create: true
        pspEnabled: true
    hostNetwork: false
    image:
      pullPolicy: IfNotPresent
      repository: quay.io/coreos/kube-state-metrics
      tag: v1.9.2
    namespaceOverride: ""
    nodeSelector: {}
    podAnnotations: {}
    podSecurityPolicy:
      annotations: {}
      enabled: true
    prometheus:
      monitor:
        additionalLabels: {}
        enabled: false
        honorLabels: false
        namespace: ""
    prometheusScrape: true
    rbac:
      create: true
    replicas: 1
    securityContext:
      enabled: true
      fsGroup: 65534
      runAsUser: 65534
    service:
      annotations: {}
      loadBalancerIP: ""
      nodePort: 0
      port: 8080
      type: ClusterIP
    serviceAccount:
      create: true
      imagePullSecrets: []
      name: null
    tolerations: []
  kubeApiServer:
    enabled: true
    relabelings: []
    serviceMonitor:
      interval: ""
      jobLabel: component
      metricRelabelings: []
      selector:
        matchLabels:
          component: apiserver
          provider: kubernetes
    tlsConfig:
      insecureSkipVerify: false
      serverName: kubernetes
  kubeControllerManager:
    enabled: true
    endpoints: []
    service:
      port: 10252
      targetPort: 10252
    serviceMonitor:
      https: false
      insecureSkipVerify: null
      interval: ""
      metricRelabelings: []
      relabelings: []
      serverName: null
  kubeDns:
    enabled: false
    service:
      dnsmasq:
        port: 10054
        targetPort: 10054
      skydns:
        port: 10055
        targetPort: 10055
    serviceMonitor:
      dnsmasqMetricRelabelings: []
      dnsmasqRelabelings: []
      interval: ""
      metricRelabelings: []
      relabelings: []
  kubeEtcd:
    enabled: true
    endpoints: []
    service:
      port: 2379
      targetPort: 2379
    serviceMonitor:
      caFile: ""
      certFile: ""
      insecureSkipVerify: false
      interval: ""
      keyFile: ""
      metricRelabelings: []
      relabelings: []
      scheme: http
      serverName: ""
  kubeProxy:
    enabled: true
    endpoints: []
    service:
      port: 10249
      targetPort: 10249
    serviceMonitor:
      https: false
      interval: ""
      metricRelabelings: []
      relabelings: []
  kubeScheduler:
    enabled: true
    endpoints: []
    service:
      port: 10251
      targetPort: 10251
    serviceMonitor:
      https: false
      insecureSkipVerify: null
      interval: ""
      metricRelabelings: []
      relabelings: []
      serverName: null
  kubeStateMetrics:
    enabled: true
    serviceMonitor:
      interval: ""
      metricRelabelings: []
      relabelings: []
  kubelet:
    enabled: true
    namespace: kube-system
    serviceMonitor:
      cAdvisorMetricRelabelings: []
      cAdvisorRelabelings:
      - sourceLabels:
        - __metrics_path__
        targetLabel: metrics_path
      https: true
      interval: ""
      metricRelabelings: []
      relabelings:
      - sourceLabels:
        - __metrics_path__
        targetLabel: metrics_path
  nameOverride: ""
  nodeExporter:
    enabled: true
    jobLabel: jobLabel
    serviceMonitor:
      interval: ""
      metricRelabelings: []
      relabelings: []
      scrapeTimeout: ""
  prometheus:
    additionalPodMonitors: []
    additionalServiceMonitors: []
    annotations: {}
    enabled: true
    ingress:
      annotations: {}
      enabled: false
      hosts: []
      labels: {}
      paths: []
      tls: []
    ingressPerReplica:
      annotations: {}
      enabled: false
      hostDomain: ""
      hostPrefix: ""
      labels: {}
      paths: []
      tlsSecretName: ""
    podDisruptionBudget:
      enabled: false
      maxUnavailable: ""
      minAvailable: 1
    podSecurityPolicy:
      allowedCapabilities: []
    prometheusSpec:
      additionalAlertManagerConfigs: []
      additionalAlertRelabelConfigs: []
      additionalPrometheusSecretsAnnotations: {}
      additionalScrapeConfigs: []
      additionalScrapeConfigsExternal: false
      affinity: {}
      alertingEndpoints: []
      configMaps: []
      containers: []
      enableAdminAPI: false
      evaluationInterval: ""
      externalLabels: {}
      externalUrl: ""
      image:
        repository: quay.io/prometheus/prometheus
        tag: v2.13.1
      listenLocal: false
      logFormat: logfmt
      logLevel: info
      nodeSelector: {}
      paused: false
      podAntiAffinity: ""
      podAntiAffinityTopologyKey: kubernetes.io/hostname
      podMetadata: {}
      podMonitorNamespaceSelector: {}
      podMonitorSelector: {}
      podMonitorSelectorNilUsesHelmValues: true
      portName: web
      priorityClassName: ""
      prometheusExternalLabelName: ""
      prometheusExternalLabelNameClear: false
      query: {}
      remoteRead: []
      remoteWrite: []
      remoteWriteDashboards: false
      replicaExternalLabelName: ""
      replicaExternalLabelNameClear: false
      replicas: 1
      resources: {}
      retention: 10d
      retentionSize: ""
      routePrefix: /
      ruleNamespaceSelector: {}
      ruleSelector: {}
      ruleSelectorNilUsesHelmValues: true
      scrapeInterval: ""
      secrets: []
      securityContext:
        fsGroup: 2000
        runAsNonRoot: true
        runAsUser: 1000
      serviceMonitorNamespaceSelector: {}
      serviceMonitorSelector: {}
      serviceMonitorSelectorNilUsesHelmValues: true
      storageSpec: {}
      thanos: {}
      tolerations: []
      walCompression: false
    service:
      annotations: {}
      clusterIP: ""
      externalIPs: []
      labels: {}
      loadBalancerIP: ""
      loadBalancerSourceRanges: []
      nodePort: 30090
      port: 9090
      sessionAffinity: ""
      targetPort: 9090
      type: ClusterIP
    serviceAccount:
      create: true
      name: ""
    serviceMonitor:
      bearerTokenFile: null
      interval: ""
      metricRelabelings: []
      relabelings: []
      scheme: ""
      selfMonitor: true
      tlsConfig: {}
    servicePerReplica:
      annotations: {}
      enabled: false
      loadBalancerSourceRanges: []
      nodePort: 30091
      port: 9090
      targetPort: 9090
      type: ClusterIP
  prometheus-node-exporter:
    affinity: {}
    configmaps: []
    endpoints: []
    extraArgs:
    - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
    - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
    extraHostVolumeMounts: []
    global:
      domain: 192.168.99.100
      imagePullSecrets: []
      rbac:
        create: true
        pspEnabled: true
    hostNetwork: true
    image:
      pullPolicy: IfNotPresent
      repository: quay.io/prometheus/node-exporter
      tag: v0.18.1
    namespaceOverride: ""
    nodeSelector: {}
    podAnnotations: {}
    podLabels:
      jobLabel: node-exporter
    prometheus:
      monitor:
        additionalLabels: {}
        enabled: false
        namespace: ""
        scrapeTimeout: 10s
    rbac:
      create: true
      pspEnabled: true
    resources: {}
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    service:
      annotations:
        prometheus.io/scrape: "true"
      nodePort: null
      port: 9100
      targetPort: 9100
      type: ClusterIP
    serviceAccount:
      create: true
      imagePullSecrets: []
      name: null
    tolerations:
    - effect: NoSchedule
      operator: Exists
  prometheusOperator:
    admissionWebhooks:
      enabled: true
      failurePolicy: Fail
      patch:
        affinity: {}
        enabled: true
        image:
          pullPolicy: IfNotPresent
          repository: jettech/kube-webhook-certgen
          tag: v1.0.0
        nodeSelector: {}
        podAnnotations: {}
        priorityClassName: ""
        resources: {}
        tolerations: []
    affinity: {}
    cleanupCustomResource: false
    configReloaderCpu: 100m
    configReloaderMemory: 25Mi
    configmapReloadImage:
      repository: quay.io/coreos/configmap-reload
      tag: v0.0.1
    createCustomResource: true
    denyNamespaces: []
    enabled: true
    hyperkubeImage:
      pullPolicy: IfNotPresent
      repository: k8s.gcr.io/hyperkube
      tag: v1.12.1
    image:
      pullPolicy: IfNotPresent
      repository: quay.io/coreos/prometheus-operator
      tag: v0.34.0
    kubeletService:
      enabled: true
      namespace: kube-system
    namespaces: {}
    nodeSelector: {}
    podAnnotations: {}
    podLabels: {}
    prometheusConfigReloaderImage:
      repository: quay.io/coreos/prometheus-config-reloader
      tag: v0.34.0
    resources: {}
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    service:
      additionalPorts: []
      annotations: {}
      clusterIP: ""
      externalIPs: []
      labels: {}
      loadBalancerIP: ""
      loadBalancerSourceRanges: []
      nodePort: 30080
      nodePortTls: 30443
      type: ClusterIP
    serviceAccount:
      create: true
      name: ""
    serviceMonitor:
      interval: ""
      metricRelabelings: []
      relabelings: []
      selfMonitor: true
    tlsProxy:
      enabled: true
      image:
        pullPolicy: IfNotPresent
        repository: squareup/ghostunnel
        tag: v1.4.1
      resources: {}
    tolerations: []
rancher_api_key: null
rancher_cluster_id: null
rancher_project_id: null
rancher_url: null
